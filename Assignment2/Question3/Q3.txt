Question 3.1

I set four candidate nodes in the first hidden_Layers, which are 50, 250,600,1000,10; and three candidate activation functions 'relu','identity' and 'tanh'. For each combination of these two parameters, I run it through 10-fold validation and get accuracy for each fold, after running 10 folds, average accuracy for this combination of parameters can be calculated.

The results are:
With hidden layer (50, 10), using activation function relu, the average accuracy to predict sentiment score is 0.912912912912913
With hidden layer (50, 10), using activation function identity, the average accuracy to predict sentiment score is 0.914914914914915
With hidden layer (50, 10), using activation function tanh, the average accuracy to predict sentiment score is 0.907907907907908
With hidden layer (250, 10), using activation function relu, the average accuracy to predict sentiment score is 0.922922922922923
With hidden layer (250, 10), using activation function identity, the average accuracy to predict sentiment score is 0.914914914914915
With hidden layer (250, 10), using activation function tanh, the average accuracy to predict sentiment score is 0.9119119119119119
With hidden layer (600, 10), using activation function relu, the average accuracy to predict sentiment score is 0.9219219219219219
With hidden layer (600, 10), using activation function identity, the average accuracy to predict sentiment score is 0.914914914914915
With hidden layer (600, 10), using activation function tanh, the average accuracy to predict sentiment score is 0.9069069069069069
With hidden layer (1000, 10), using activation function relu, the average accuracy to predict sentiment score is 0.9169169169169169
With hidden layer (1000, 10), using activation function identity, the average accuracy to predict sentiment score is 0.914914914914915
With hidden layer (1000, 10), using activation function tanh, the average accuracy to predict sentiment score is 0.9139139139139141

Through Comparing the results above, I can say that using first hidden layer with nodes 250 and activation function relu are the optimal parameters.


Question 3.2

Using these parameters, training the model on the same training set can result in accuracy 1.0.

Question 3.3

Using average embeddings to compute the review feature vector. I still set four candidate nodes in the first hidden_Layers, which are 50, 250,600,1000,10; and three candidate activation functions 'relu','identity' and 'tanh'. I got the results like these:

With hidden layer (50, 10), using activation function relu, the average accuracy to predict sentiment score is 0.922922922922923
With hidden layer (50, 10), using activation function identity, the average accuracy to predict sentiment score is 0.9189189189189191
With hidden layer (50, 10), using activation function tanh, the average accuracy to predict sentiment score is 0.922922922922923
With hidden layer (250, 10), using activation function relu, the average accuracy to predict sentiment score is 0.922922922922923
With hidden layer (250, 10), using activation function identity, the average accuracy to predict sentiment score is 0.9169169169169169
With hidden layer (250, 10), using activation function tanh, the average accuracy to predict sentiment score is 0.9239239239239241
With hidden layer (600, 10), using activation function relu, the average accuracy to predict sentiment score is 0.9219219219219219
With hidden layer (600, 10), using activation function identity, the average accuracy to predict sentiment score is 0.917917917917918
With hidden layer (600, 10), using activation function tanh, the average accuracy to predict sentiment score is 0.9159159159159158
With hidden layer (1000, 10), using activation function relu, the average accuracy to predict sentiment score is 0.927927927927928
With hidden layer (1000, 10), using activation function identity, the average accuracy to predict sentiment score is 0.9189189189189191
With hidden layer (1000, 10), using activation function tanh, the average accuracy to predict sentiment score is 0.9189189189189191

The first hidden layer with 1000 nodes and use activation 'relu' can gives the best result.

Fitting it on the entire training set, I got accuracy 94.55%.

Question 3.4

In question 3.4, I have three parameters need to select the best number to generate best result. I set number of components to candidates 300, 600, 900; set nodes of the first layer to 250 and 600 and set activation function as 'relu' since it has the best performance in question 3.1 -3.3.

Here are the results I got:
with 300 components:
With hidden layer (250, 10), using activation function relu, the average accuracy to predict sentiment score is 0.9309309309309308
With hidden layer (600, 10), using activation function relu, the average accuracy to predict sentiment score is 0.9419419419419419
with 600 components:
With hidden layer (250, 10), using activation function relu, the average accuracy to predict sentiment score is 0.924924924924925
With hidden layer (600, 10), using activation function relu, the average accuracy to predict sentiment score is 0.92992992992993
with 900 components:
With hidden layer (250, 10), using activation function relu, the average accuracy to predict sentiment score is 0.937937937937938
With hidden layer (600, 10), using activation function relu, the average accuracy to predict sentiment score is 0.9319319319319319

Hence, I'll use 300 as my number of components, 600 as hidden nodes and 'relu' as activation function.

After training on the training set, I got accuracy 0.9897.


Question 3.5
['00', '000', '0000000', '00a', '00am'] are the top 5 topics I got, but it seems not right.


